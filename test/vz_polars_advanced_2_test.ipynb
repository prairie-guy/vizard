{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# Vizard Advanced Polars Test Suite 2\n\n**Purpose:** Test fixes and new features added after vz_polars_advanced_test.ipynb\n\n**Categories:**\n1. BIN fixes (actual bin values, starting at syntax) - 4 tests\n2. NULL handling (DROP_NULLS, FILL_NULLS, IS_NULL) - 9 tests\n3. DATA/SEP I/O combinations - 10 tests\n\n**Total:** ~23 tests"
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from altair.datasets import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext vizard_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cc HELP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cc RESET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse same datasets from original test\n",
    "df_cars = pl.DataFrame(data.cars())\n",
    "print(f\"cars shape: {df_cars.shape}\")\n",
    "df_cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = pl.DataFrame(data.seattle_weather())\n",
    "print(f\"seattle_weather shape: {df_weather.shape}\")\n",
    "df_weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Create Test DataFrames with Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": "# DataFrame with actual nulls and NaN values\ndf_nulls = pl.DataFrame({\n    'id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n    'name': ['Alice', None, 'Charlie', 'David', 'Eve', None, 'George', 'Helen', 'Ivan', None],\n    'value': [100.0, 200.0, None, 400.0, float('nan'), 600.0, 700.0, float('nan'), 900.0, 1000.0],\n    'score': [85.5, float('nan'), 92.0, 90.0, None, 88.0, 87.5, None, 92.0, 87.0]\n})\nprint(\"Test DataFrame with actual nulls (None) and NaN:\")\ndf_nulls"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": "# DataFrame for multi-column null testing\ndf_nulls_multi = pl.DataFrame({\n    'gene': ['BRCA1', 'TP53', 'EGFR', 'KRAS', 'MYC'],\n    'expression': [5.2, None, 3.8, 4.1, float('nan')],\n    'pvalue': [0.001, None, float('nan'), 0.05, 0.003],\n    'significant': [True, True, False, True, False]\n})\nprint(\"Multi-column null test DataFrame:\")\ndf_nulls_multi"
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "---\n",
    "# Category 1: BIN Fixes (4 tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Test 1.1: BIN - Actual Bin Values (Equal Width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before: Check weight range\n",
    "print(f\"Weight range: {df_cars['Weight_in_lbs'].min()} - {df_cars['Weight_in_lbs'].max()}\")\n",
    "df_cars.select(['Name', 'Weight_in_lbs']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should produce bin values: 1500, 2000, 2500, 3000... (not 0, 1, 2, 3...)\n",
    "%cc DATA df_cars SELECT Name, Weight_in_lbs BIN Weight_in_lbs by 500 as weight_bin ||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Test 1.2: BIN - With Starting Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should produce bins starting at 2000: 2000, 2500, 3000, 3500...\n",
    "%cc DATA df_cars SELECT Name, Weight_in_lbs BIN Weight_in_lbs by 500 starting at 2000 as weight_bin ||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Test 1.3: BIN - Year Data (Fix for Test 12.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before: Check Year range\n",
    "print(f\"Year range: {df_cars['Year'].min()} - {df_cars['Year'].max()}\")\n",
    "df_cars.select(['Name', 'Year']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should produce: 70, 75, 80 (for years 70-74, 75-79, 80-84)\n",
    "# NOT astronomical numbers like 75738240000000000\n",
    "%cc DATA df_cars SELECT Name, Origin, Year CAST Year to integer BIN Year by 5 as year_range GROUP by Origin, year_range aggregating count() as n_cars ||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Test 1.4: BIN - MPG with Ascending Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should produce bins: 10, 15, 20, 25, 30, 35... ordered\n",
    "%cc DATA df_cars SELECT Name, Miles_per_Gallon BIN Miles_per_Gallon by 5 ascending as mpg_bin HEAD 20 ||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "---\n",
    "# Category 2: NULL Handling (9 tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## Test 2.1: DROP_NULLS - Single Column (Various Null Types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": "# Before: Has None in name column (rows 2, 6, 10)\nprint(\"Before DROP_NULLS:\")\ndf_nulls"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": "# Should drop rows 2, 6, 10 (where name is None)\n# Keep rows: 1, 3, 4, 5, 7, 8, 9 (Alice, Charlie, David, Eve, George, Helen, Ivan)\n%cc DATA df_nulls DROP_NULLS name ||"
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## Test 2.2: DROP_NULLS - Multiple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": "# Before: Has None and NaN in expression and pvalue columns\nprint(\"Before DROP_NULLS:\")\ndf_nulls_multi"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": "# Should drop rows where expression OR pvalue is None/NaN\n# expression: row 2 (None), row 5 (NaN)\n# pvalue: row 2 (None), row 3 (NaN)\n# Keep only: rows 1, 4, 5 BUT row 5 has NaN in expression, so keep only rows 1, 4 (BRCA1, KRAS)\n%cc DATA df_nulls_multi DROP_NULLS expression, pvalue ||"
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "## Test 2.3: FILL_NULLS - Single Column with Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": "# Before: value has None (row 3) and NaN (rows 5, 8)\nprint(\"Before FILL_NULLS:\")\ndf_nulls.select(['id', 'name', 'value'])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": "# Should fill None and NaN with -1 (rows 3, 5, 8)\n%cc DATA df_nulls SELECT id, name, value FILL_NULLS value with -1 ||"
  },
  {
   "cell_type": "markdown",
   "id": "cell-33",
   "metadata": {},
   "source": [
    "## Test 2.4: FILL_NULLS - Multiple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-34",
   "metadata": {},
   "outputs": [],
   "source": "# Before: expression and pvalue have None and NaN\nprint(\"Before FILL_NULLS:\")\ndf_nulls_multi"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": "# Should fill None and NaN in both columns with 0\n%cc DATA df_nulls_multi FILL_NULLS expression, pvalue with 0 ||"
  },
  {
   "cell_type": "markdown",
   "id": "cell-36",
   "metadata": {},
   "source": [
    "## Test 2.5: IS_NULL - Create Boolean Flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-37",
   "metadata": {},
   "outputs": [],
   "source": "# Before: name has None at rows 2, 6, 10\nprint(\"Before IS_NULL:\")\ndf_nulls.select(['id', 'name'])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-38",
   "metadata": {},
   "outputs": [],
   "source": "# Should create boolean column: True for rows 2, 6, 10 (where name is None)\n%cc DATA df_nulls SELECT id, name IS_NULL name as name_is_missing ||"
  },
  {
   "cell_type": "markdown",
   "id": "cell-39",
   "metadata": {},
   "source": [
    "## Test 2.6: Null Handling - Case Insensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-40",
   "metadata": {},
   "outputs": [],
   "source": "# Test NaN handling in numeric columns (score has NaN at rows 2, 8 and None at rows 5, 8)\nprint(\"Before (score has NaN and None):\")\ndf_nulls.select(['id', 'score'])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-41",
   "metadata": {},
   "outputs": [],
   "source": "# Should drop rows 2, 5, 8 (NaN, None, None) from numeric column\n%cc DATA df_nulls SELECT id, score DROP_NULLS score ||"
  },
  {
   "cell_type": "markdown",
   "id": "cell-42",
   "metadata": {},
   "source": [
    "## Test 2.7: Null Handling with Real Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if cars dataset has any nulls\n",
    "print(\"Null counts in cars dataset:\")\n",
    "df_cars.null_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Horsepower has nulls, drop them\n",
    "%cc DATA df_cars DROP_NULLS Horsepower SELECT Name, Horsepower HEAD 10 ||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-45",
   "metadata": {},
   "source": [
    "## Test 2.8: Combination - IS_NULL then FILTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create flag, then filter to only missing values\n",
    "%cc DATA df_nulls_multi IS_NULL expression as expr_missing FILTER expr_missing == true ||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-47",
   "metadata": {},
   "source": [
    "## Test 2.9: Combination - FILL_NULLS then GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill nulls, then aggregate\n",
    "%cc DATA df_nulls_multi FILL_NULLS expression with 0 GROUP by significant aggregating mean(expression) as avg_expr, count() as n ||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-49",
   "metadata": {},
   "source": [
    "---\n",
    "# Category 3: DATA/SEP I/O Testing (10 tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-50",
   "metadata": {},
   "source": [
    "## Create Test Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test CSV file\n",
    "test_data = pl.DataFrame({\n",
    "    'gene': ['BRCA1', 'TP53', 'EGFR'],\n",
    "    'expression': [5.2, 8.1, 3.4],\n",
    "    'pvalue': [0.001, 0.003, 0.05]\n",
    "})\n",
    "\n",
    "test_data.write_csv('test_data.csv')\n",
    "print(\"Created test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test TSV file\n",
    "test_data.write_csv('test_data.tsv', separator='\\t')\n",
    "print(\"Created test_data.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ambiguous .dat file (tab-separated)\n",
    "test_data.write_csv('test_data.dat', separator='\\t')\n",
    "print(\"Created test_data.dat (tab-separated)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-54",
   "metadata": {},
   "source": [
    "## Test 3.1: DATA - CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cc DATA test_data.csv ||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-56",
   "metadata": {},
   "source": [
    "## Test 3.2: DATA - TSV File with SEP \\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cc DATA test_data.tsv SEP \\t ||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-58",
   "metadata": {},
   "source": [
    "## Test 3.3: DATA - .dat File with SEP csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should try comma separator (but file is tab-separated, so may fail - that's ok)\n",
    "%cc DATA test_data.dat SEP csv ||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-60",
   "metadata": {},
   "source": [
    "## Test 3.4: DATA - .dat File with SEP tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should work - file is tab-separated\n",
    "%cc DATA test_data.dat SEP tsv ||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-62",
   "metadata": {},
   "source": [
    "## Test 3.5: DATA - .dat File with SEP both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should try TSV first (succeed), fallback to CSV not needed\n",
    "%cc DATA test_data.dat SEP both ||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-64",
   "metadata": {},
   "source": [
    "## Test 3.6: DATA - DataFrame Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should use df_cars directly\n",
    "%cc DATA df_cars SELECT Name, Origin HEAD 5 ||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-66",
   "metadata": {},
   "source": [
    "## Test 3.7: DATA - Altair Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should load from altair.datasets\n",
    "%cc DATA cars HEAD 10 ||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-68",
   "metadata": {},
   "source": [
    "## Test 3.8: DATA - CSV with Explicit SEP ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cc DATA test_data.csv SEP , ||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-70",
   "metadata": {},
   "source": [
    "## Test 3.9: DATA - URL (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-71",
   "metadata": {},
   "outputs": [],
   "source": "# Test with a known public CSV URL\n%cc DATA https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv HEAD 5 ||"
  },
  {
   "cell_type": "markdown",
   "id": "cell-72",
   "metadata": {},
   "source": "## Test 3.10: DATA - Chained with Wrangling"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TSV and immediately wrangle\n",
    "%cc DATA test_data.tsv SEP \\t FILTER pvalue < 0.01 ||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-74",
   "metadata": {},
   "source": [
    "---\n",
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove test files\n",
    "import os\n",
    "for file in ['test_data.csv', 'test_data.tsv', 'test_data.dat']:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        print(f\"Removed {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-76",
   "metadata": {},
   "source": "---\n# Summary\n\n**Tests completed:** 23 tests total\n\n**Category 1 - BIN Fixes (4 tests):**\n- Actual bin values (lower bounds)\n- Starting at syntax\n- Year data binning fix\n- Ascending order\n\n**Category 2 - NULL Handling (9 tests):**\n- DROP_NULLS single/multiple columns\n- FILL_NULLS with constants\n- IS_NULL boolean flags\n- Case insensitivity\n- Real dataset nulls\n- Combinations with other operations\n\n**Category 3 - DATA/SEP I/O (10 tests):**\n- CSV files\n- TSV files with SEP variants\n- .dat files with SEP csv/tsv/both\n- DataFrame variables\n- Altair datasets\n- CSV URL loading (JSON URLs not supported by Polars)\n- Chained wrangling\n\n**Next steps:**\n1. Run all tests and identify failures\n2. Report issues for CLAUDE.md updates\n3. Iterate until all pass"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}